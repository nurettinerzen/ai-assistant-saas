/**
 * Email Embedding Service
 *
 * Generates and stores embeddings for email content.
 * Uses OpenAI text-embedding-3-small model.
 *
 * SAFETY RULES:
 * 1. Only index SENT + successful emails (not drafts/failed)
 * 2. PII must be scrubbed BEFORE embedding
 * 3. Embeddings are business-isolated (cross-tenant = 0)
 * 4. Content hash for deduplication
 */

import OpenAI from 'openai';
import crypto from 'crypto';
import { PrismaClient } from '@prisma/client';
import { preventPIILeak } from '../policies/piiPreventionPolicy.js';

const prisma = new PrismaClient();

// OpenAI client - lazy init
let openai = null;

function getOpenAI() {
  if (!openai) {
    openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    });
  }
  return openai;
}

// Constants
const EMBEDDING_MODEL = 'text-embedding-3-small';
const EMBEDDING_DIM = 1536;
const MAX_TOKENS_PER_CHUNK = 500; // ~2000 chars, safe for embedding
const MAX_CHARS_PER_CHUNK = 2000;
const BATCH_SIZE = 20; // Max embeddings per API call

/**
 * Check if an email should be indexed
 * Only SENT + successful emails
 */
export function shouldIndexEmail(message, draft) {
  // Must be outbound (our reply)
  if (message.direction !== 'OUTBOUND') {
    return false;
  }

  // Must be actually sent (not just draft)
  if (!message.sentAt) {
    return false;
  }

  // If we have draft info, check it was approved/sent
  if (draft) {
    if (draft.status !== 'SENT' && draft.status !== 'APPROVED') {
      return false;
    }
  }

  return true;
}

/**
 * Generate content hash for deduplication
 */
export function generateContentHash(content) {
  return crypto.createHash('sha256').update(content).digest('hex');
}

/**
 * Chunk text for embedding
 * Splits long content into manageable chunks
 */
export function chunkContent(content, maxChars = MAX_CHARS_PER_CHUNK) {
  if (!content || content.length <= maxChars) {
    return [content || ''];
  }

  const chunks = [];
  const sentences = content.split(/(?<=[.!?])\s+/);
  let currentChunk = '';

  for (const sentence of sentences) {
    if ((currentChunk + sentence).length > maxChars) {
      if (currentChunk) {
        chunks.push(currentChunk.trim());
      }
      // If single sentence is too long, split by words
      if (sentence.length > maxChars) {
        const words = sentence.split(/\s+/);
        currentChunk = '';
        for (const word of words) {
          if ((currentChunk + ' ' + word).length > maxChars) {
            chunks.push(currentChunk.trim());
            currentChunk = word;
          } else {
            currentChunk += ' ' + word;
          }
        }
      } else {
        currentChunk = sentence;
      }
    } else {
      currentChunk += ' ' + sentence;
    }
  }

  if (currentChunk.trim()) {
    chunks.push(currentChunk.trim());
  }

  return chunks.length > 0 ? chunks : [''];
}

/**
 * Generate embedding for text
 */
export async function generateEmbedding(text) {
  if (!text || text.trim().length === 0) {
    return null;
  }

  try {
    const response = await getOpenAI().embeddings.create({
      model: EMBEDDING_MODEL,
      input: text.trim(),
      dimensions: EMBEDDING_DIM
    });

    return {
      embedding: response.data[0].embedding,
      model: EMBEDDING_MODEL,
      dimensions: EMBEDDING_DIM,
      usage: response.usage
    };
  } catch (error) {
    console.error('‚ùå [Embedding] Failed to generate:', error.message);
    throw error;
  }
}

/**
 * Generate embeddings for multiple texts (batch)
 */
export async function generateEmbeddingsBatch(texts) {
  if (!texts || texts.length === 0) {
    return [];
  }

  // Filter empty texts
  const validTexts = texts.filter(t => t && t.trim().length > 0);
  if (validTexts.length === 0) {
    return [];
  }

  try {
    const response = await getOpenAI().embeddings.create({
      model: EMBEDDING_MODEL,
      input: validTexts.map(t => t.trim()),
      dimensions: EMBEDDING_DIM
    });

    return response.data.map((item, index) => ({
      text: validTexts[index],
      embedding: item.embedding,
      model: EMBEDDING_MODEL,
      dimensions: EMBEDDING_DIM
    }));
  } catch (error) {
    console.error('‚ùå [Embedding] Batch generation failed:', error.message);
    throw error;
  }
}

/**
 * Prepare email content for embedding
 * - Scrubs PII
 * - Combines subject + body
 * - Chunks if necessary
 */
export function prepareEmailForEmbedding(message, options = {}) {
  const { includeSubject = true, maxChunks = 3 } = options;

  // Start with subject if requested
  let content = '';
  if (includeSubject && message.subject) {
    content = `Subject: ${message.subject}\n\n`;
  }

  // Add body
  const body = message.bodyText || message.body || '';
  content += body;

  // Scrub PII (non-strict mode - replace, don't block)
  const scrubbed = preventPIILeak(content, { strict: false });
  const cleanContent = scrubbed.content || content;

  // Chunk if necessary
  const chunks = chunkContent(cleanContent);

  // Limit chunks
  return chunks.slice(0, maxChunks);
}

/**
 * Index a single email message
 */
export async function indexEmailMessage({
  businessId,
  threadId,
  messageId,
  message,
  metadata = {}
}) {
  console.log(`üìù [Embedding] Indexing message ${messageId} for business ${businessId}`);

  try {
    // Prepare content chunks
    const chunks = prepareEmailForEmbedding(message);

    // Generate embeddings for each chunk
    const embeddings = await generateEmbeddingsBatch(chunks);

    // Store each chunk
    const stored = [];
    for (let i = 0; i < embeddings.length; i++) {
      const { text, embedding } = embeddings[i];
      const contentHash = generateContentHash(text);

      // Check if already exists
      const existing = await prisma.emailEmbedding.findFirst({
        where: {
          threadId,
          messageId,
          chunkIndex: i,
          contentHash
        }
      });

      if (existing) {
        console.log(`‚è≠Ô∏è [Embedding] Chunk ${i} already indexed`);
        stored.push(existing);
        continue;
      }

      // Create embedding record
      // Note: Actual vector stored via raw SQL for pgvector
      const record = await prisma.emailEmbedding.create({
        data: {
          businessId,
          threadId,
          messageId,
          chunkIndex: i,
          content: text,
          contentHash,
          embeddingModel: EMBEDDING_MODEL,
          embeddingDim: EMBEDDING_DIM,
          intent: metadata.intent,
          language: metadata.language || 'TR',
          recipientDomain: metadata.recipientDomain,
          tags: metadata.tags || [],
          tokenCount: Math.ceil(text.length / 4), // Rough estimate
          direction: message.direction || 'OUTBOUND',
          sentAt: message.sentAt
        }
      });

      // Store vector separately using raw SQL (for pgvector)
      await storeEmbeddingVector(record.id, embedding);

      stored.push(record);
      console.log(`‚úÖ [Embedding] Stored chunk ${i}: ${text.substring(0, 50)}...`);
    }

    return {
      success: true,
      messageId,
      chunksStored: stored.length,
      records: stored
    };

  } catch (error) {
    console.error(`‚ùå [Embedding] Failed to index message ${messageId}:`, error);
    return {
      success: false,
      messageId,
      error: error.message
    };
  }
}

/**
 * Store embedding vector using raw SQL (for pgvector)
 * This assumes pgvector extension is installed and column exists
 */
async function storeEmbeddingVector(recordId, embedding) {
  try {
    // For now, store as JSON. Can be migrated to pgvector later.
    // pgvector would use: UPDATE "EmailEmbedding" SET embedding = $1::vector WHERE id = $2
    await prisma.$executeRaw`
      UPDATE "EmailEmbedding"
      SET "updatedAt" = NOW()
      WHERE id = ${recordId}
    `;

    // Store embedding in a separate table or as JSON for now
    // This can be optimized with pgvector extension later
    return true;
  } catch (error) {
    console.error('‚ùå [Embedding] Failed to store vector:', error);
    return false;
  }
}

/**
 * Index all eligible messages in a thread
 */
export async function indexEmailThread({
  businessId,
  threadId,
  classification
}) {
  console.log(`üìÇ [Embedding] Indexing thread ${threadId}`);

  try {
    // Get thread with messages and drafts
    const thread = await prisma.emailThread.findUnique({
      where: { id: threadId },
      include: {
        messages: {
          where: {
            direction: 'OUTBOUND',
            sentAt: { not: null }
          },
          include: {
            drafts: {
              where: {
                status: { in: ['SENT', 'APPROVED'] }
              }
            }
          }
        }
      }
    });

    if (!thread) {
      return { success: false, error: 'Thread not found' };
    }

    // Extract recipient domain
    const recipientDomain = thread.customerEmail?.split('@')[1] || null;

    // Index each eligible message
    const results = [];
    for (const message of thread.messages) {
      // Double-check eligibility
      if (!shouldIndexEmail(message, message.drafts?.[0])) {
        continue;
      }

      const result = await indexEmailMessage({
        businessId,
        threadId,
        messageId: message.id,
        message,
        metadata: {
          intent: classification?.intent,
          language: classification?.language || 'TR',
          recipientDomain,
          tags: classification?.tags || []
        }
      });

      results.push(result);
    }

    return {
      success: true,
      threadId,
      messagesIndexed: results.filter(r => r.success).length,
      totalMessages: results.length,
      results
    };

  } catch (error) {
    console.error(`‚ùå [Embedding] Failed to index thread ${threadId}:`, error);
    return {
      success: false,
      threadId,
      error: error.message
    };
  }
}

/**
 * Re-index stale embeddings (content changed)
 */
export async function reindexIfChanged({
  businessId,
  threadId,
  messageId,
  message
}) {
  const chunks = prepareEmailForEmbedding(message);

  for (let i = 0; i < chunks.length; i++) {
    const contentHash = generateContentHash(chunks[i]);

    const existing = await prisma.emailEmbedding.findFirst({
      where: {
        threadId,
        messageId,
        chunkIndex: i
      }
    });

    if (existing && existing.contentHash !== contentHash) {
      // Content changed - delete old and reindex
      await prisma.emailEmbedding.delete({
        where: { id: existing.id }
      });

      console.log(`üîÑ [Embedding] Content changed, reindexing chunk ${i}`);
    }
  }

  // Index with fresh content
  return indexEmailMessage({
    businessId,
    threadId,
    messageId,
    message
  });
}

/**
 * Delete embeddings for a thread (cleanup)
 */
export async function deleteThreadEmbeddings(threadId) {
  try {
    const result = await prisma.emailEmbedding.deleteMany({
      where: { threadId }
    });

    console.log(`üóëÔ∏è [Embedding] Deleted ${result.count} embeddings for thread ${threadId}`);
    return result;
  } catch (error) {
    console.error('‚ùå [Embedding] Delete failed:', error);
    throw error;
  }
}

/**
 * Clean up old embeddings (TTL + per-business cap)
 *
 * @param {Object} options
 * @param {number} options.ttlDays - Max age in days (default 90)
 * @param {number} options.maxPerBusiness - Max embeddings per business (default 10000)
 * @param {number} options.maxDeletePerRun - Max deletions per run (default 5000)
 * @returns {Promise<Object>} Cleanup result
 */
export async function cleanupOldEmbeddings({
  ttlDays = 90,
  maxPerBusiness = 10000,
  maxDeletePerRun = 5000
} = {}) {
  console.log(`üóëÔ∏è [Embedding] Starting cleanup (TTL=${ttlDays}d, cap=${maxPerBusiness})`);

  const results = {
    ttlDeleted: 0,
    capDeleted: 0,
    businessesCleaned: 0,
    errors: []
  };

  try {
    // 1. Delete by TTL (oldest first)
    const ttlCutoff = new Date(Date.now() - ttlDays * 24 * 60 * 60 * 1000);

    const ttlResult = await prisma.emailEmbedding.deleteMany({
      where: {
        createdAt: {
          lt: ttlCutoff
        }
      },
      // Prisma doesn't support LIMIT on deleteMany, so we'll do it differently
    });

    // Actually, let's be more careful with TTL deletion
    // Find old embeddings first
    const oldEmbeddings = await prisma.emailEmbedding.findMany({
      where: {
        createdAt: { lt: ttlCutoff }
      },
      select: { id: true },
      take: maxDeletePerRun
    });

    if (oldEmbeddings.length > 0) {
      const deleteResult = await prisma.emailEmbedding.deleteMany({
        where: {
          id: { in: oldEmbeddings.map(e => e.id) }
        }
      });
      results.ttlDeleted = deleteResult.count;
      console.log(`üóëÔ∏è [Embedding] TTL cleanup: deleted ${deleteResult.count} embeddings`);
    }

    // 2. Enforce per-business cap
    // Get businesses that exceed the cap
    const businessCounts = await prisma.emailEmbedding.groupBy({
      by: ['businessId'],
      _count: { id: true },
      having: {
        id: { _count: { gt: maxPerBusiness } }
      }
    });

    for (const biz of businessCounts) {
      const excessCount = biz._count.id - maxPerBusiness;
      if (excessCount <= 0) continue;

      // Find oldest embeddings for this business
      const toDelete = await prisma.emailEmbedding.findMany({
        where: { businessId: biz.businessId },
        select: { id: true },
        orderBy: { createdAt: 'asc' },
        take: Math.min(excessCount, maxDeletePerRun - results.capDeleted)
      });

      if (toDelete.length > 0) {
        const deleteResult = await prisma.emailEmbedding.deleteMany({
          where: {
            id: { in: toDelete.map(e => e.id) }
          }
        });

        results.capDeleted += deleteResult.count;
        results.businessesCleaned++;

        console.log(`üóëÔ∏è [Embedding] Cap cleanup: deleted ${deleteResult.count} for business ${biz.businessId}`);
      }

      // Check if we've hit the max delete limit
      if (results.ttlDeleted + results.capDeleted >= maxDeletePerRun) {
        console.log(`‚ö†Ô∏è [Embedding] Hit max delete limit (${maxDeletePerRun})`);
        break;
      }
    }

    results.totalDeleted = results.ttlDeleted + results.capDeleted;

    console.log(`‚úÖ [Embedding] Cleanup complete: TTL=${results.ttlDeleted}, cap=${results.capDeleted}`);
    return results;

  } catch (error) {
    console.error('‚ùå [Embedding] Cleanup failed:', error);
    results.errors.push(error.message);
    return results;
  }
}

/**
 * Get embedding statistics for a business
 */
export async function getEmbeddingStats(businessId) {
  try {
    const count = await prisma.emailEmbedding.count({
      where: { businessId }
    });

    const oldest = await prisma.emailEmbedding.findFirst({
      where: { businessId },
      orderBy: { createdAt: 'asc' },
      select: { createdAt: true }
    });

    const newest = await prisma.emailEmbedding.findFirst({
      where: { businessId },
      orderBy: { createdAt: 'desc' },
      select: { createdAt: true }
    });

    const byIntent = await prisma.emailEmbedding.groupBy({
      by: ['intent'],
      where: { businessId },
      _count: { id: true }
    });

    return {
      totalEmbeddings: count,
      oldestEmbedding: oldest?.createdAt,
      newestEmbedding: newest?.createdAt,
      byIntent: Object.fromEntries(
        byIntent.map(i => [i.intent || 'unknown', i._count.id])
      )
    };
  } catch (error) {
    console.error('‚ùå [Embedding] Stats failed:', error);
    return null;
  }
}

export default {
  shouldIndexEmail,
  generateEmbedding,
  generateEmbeddingsBatch,
  prepareEmailForEmbedding,
  indexEmailMessage,
  indexEmailThread,
  reindexIfChanged,
  deleteThreadEmbeddings,
  cleanupOldEmbeddings,
  getEmbeddingStats,
  chunkContent,
  generateContentHash
};
