/**
 * Step 5: Build LLM Request
 *
 * - Applies tool gating policy
 * - Builds Gemini request with gated tools
 * - Returns chat session and request configuration
 */

import { GoogleGenerativeAI } from '@google/generative-ai';
import { applyToolGatingPolicy } from '../../../policies/toolGatingPolicy.js';
import { convertToolsToGeminiFunctions as convertToolsToGemini } from '../../../services/gemini-utils.js';

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

export async function buildLLMRequest(params) {
  const {
    systemPrompt,
    conversationHistory,
    userMessage,
    classification,
    routingResult,
    state,
    toolsAll,
    metrics,
    assistant,
    business
  } = params;

  // STEP 0: Enhance system prompt with known customer info
  // SECURITY: Only send non-PII identifiers to LLM, not actual customer data
  let enhancedSystemPrompt = systemPrompt;
  if (state.extractedSlots && Object.keys(state.extractedSlots).length > 0) {
    const knownInfo = [];
    // Only include identifiers, not actual PII values
    if (state.extractedSlots.customer_name) {
      knownInfo.push(`Customer name mentioned`);
    }
    if (state.extractedSlots.phone) {
      knownInfo.push(`Phone number provided`);
    }
    if (state.extractedSlots.order_number) {
      knownInfo.push(`Order #${state.extractedSlots.order_number}`); // Order number is OK
    }
    if (state.extractedSlots.email) {
      knownInfo.push(`Email mentioned`);
    }

    if (knownInfo.length > 0) {
      enhancedSystemPrompt += `\n\nCustomer Context: ${knownInfo.join(', ')} - Use tools to retrieve actual data`;
      console.log('ðŸ“ [BuildLLMRequest] Added context flags (no PII):', knownInfo.length, 'indicators');
    }
  }

  // Callback precondition guidance (belt-and-suspenders with toolLoop precondition check)
  // LLM should ask for name/phone BEFORE calling create_callback
  if (!state.extractedSlots?.customer_name || !state.extractedSlots?.phone) {
    enhancedSystemPrompt += `\n\nKRÄ°TÄ°K: create_callback aracÄ±nÄ± Ã§aÄŸÄ±rmadan Ã–NCE mÃ¼ÅŸterinin adÄ±nÄ± ve telefon numarasÄ±nÄ± Ã¶ÄŸren. Bu bilgiler olmadan geri arama kaydÄ± oluÅŸturamazsÄ±n.`;
  }

  if (state.callbackFlow?.pending || state.activeFlow === 'CALLBACK_REQUEST') {
    enhancedSystemPrompt += `

## CALLBACK AKIÅžI (DETERMINISTIC)
- Bu konuÅŸma geri arama talebi akÄ±ÅŸÄ±nda.
- SADECE ad-soyad ve telefon bilgisini topla.
- SipariÅŸ numarasÄ±, telefon son 4, kimlik doÄŸrulama isteme.
- create_callback Ã§aÄŸrÄ±sÄ±nda topic sorusu sorma; topic otomatik Ã¼retilecek.
- Ad-soyad ve telefon mevcutsa create_callback Ã§aÄŸÄ±r, yoksa sadece eksik alanÄ± sor.`;
  }

  // ========================================
  // KB_ONLY MODE: Inject channel restriction prompt
  // ========================================
  if (params.channelMode === 'KB_ONLY') {
    const linksList = Object.entries(params.helpLinks || {})
      .filter(([, v]) => v)
      .map(([k, v]) => `- ${k}: ${v}`)
      .join('\n');

    enhancedSystemPrompt += `

## KB_ONLY MOD (KRÄ°TÄ°K!)
Bu kanal sadece bilgi bankasÄ± ve genel yardÄ±m iÃ§in aÃ§Ä±ktÄ±r.

YASAKLAR:
- KiÅŸisel sipariÅŸ/Ã¶deme/iade/kargo bilgisi verme
- "Kontrol ediyorum", "bakÄ±yorum" gibi tool varmÄ±ÅŸ gibi davranma
- SipariÅŸ durumu, teslimat tarihi, Ã¶deme tutarÄ± gibi claim yapma
- Link uydurma â€” sadece aÅŸaÄŸÄ±daki linkleri kullan

${linksList ? `YARDIM LÄ°NKLERÄ°:\n${linksList}` : 'Link bilgisi yok â€” "destek ekibimize ulaÅŸabilirsiniz" yÃ¶nlendirmesi yap.'}

DAVRANIÅž:
- Genel bilgi sorularÄ±na (iade sÃ¼resi, kargo politikasÄ±, Ã¼yelik) Bilgi BankasÄ±'ndan cevap ver
- KiÅŸisel veri sorusu gelirse: kÄ±sa sÄ±nÄ±r aÃ§Ä±kla + yardÄ±m linki/destek yÃ¶nlendirmesi yap
- DoÄŸal ve kÄ±sa konuÅŸ, robotik olma`;

    console.log('ðŸ”’ [BuildLLMRequest] KB_ONLY prompt injected');
  }

  // ========================================
  // ARCHITECTURE CHANGE: Inject verification & dispute context for LLM
  // ========================================
  // LLM now handles verification conversation naturally.
  // We inject context so it knows what's pending.
  // SCOPE: Only inject for flows that actually require PII verification.
  // Stock, product inquiry etc. should NEVER see verification guidance.
  const VERIFICATION_FLOWS = ['ORDER_STATUS', 'DEBT_INQUIRY', 'TRACKING_INFO', 'ACCOUNT_LOOKUP'];
  // Only inject verification guidance if we're actually in a verification-relevant flow.
  // When activeFlow is null (e.g. after post-result reset), also check if there's a recent
  // stock context â€” if so, this is NOT a verification scenario.
  const hasRecentStockContext = !!state.lastStockContext || state.anchor?.type === 'STOCK';
  const isVerificationRelevant = !hasRecentStockContext &&
    (!state.activeFlow || VERIFICATION_FLOWS.includes(state.activeFlow));

  if (state.verificationContext && isVerificationRelevant) {
    const vc = state.verificationContext;
    const verificationGuidance = `

## DOÄžRULAMA DURUMU (Verification Context)
- Durum: ${vc.status}
- Beklenen bilgi: ${vc.pendingField === 'name' ? 'Ad-soyad' : vc.pendingField === 'phone' ? 'Telefon numarasÄ±' : vc.pendingField}
- Deneme sayÄ±sÄ±: ${vc.attempts}/3

KURALLAR:
- KullanÄ±cÄ±nÄ±n son mesajÄ±nÄ± baÄŸlam iÃ§inde yorumla
- EÄŸer kullanÄ±cÄ± doÄŸrulama bilgisi verdiyse, customer_data_lookup tool'unu verification_input parametresiyle Ã§aÄŸÄ±r
- EÄŸer kullanÄ±cÄ± farklÄ± bir soru sorduysa, soruyu cevapla ama doÄŸrulama ihtiyacÄ±nÄ± da hatÄ±rlat
- AynÄ± cÃ¼mleyi tekrar etme â€” her seferinde farklÄ± ve doÄŸal konuÅŸ
- YanlÄ±ÅŸ anladÄ±ÄŸÄ±nÄ± fark edersen "SanÄ±rÄ±m bir karÄ±ÅŸÄ±klÄ±k oldu..." diyebilirsin
- "LÃ¼tfen ad-soyadÄ±nÄ±zÄ± yazÄ±nÄ±z" gibi form cÃ¼mleleri KULLANMA`;

    enhancedSystemPrompt += verificationGuidance;
    console.log('ðŸ” [BuildLLMRequest] Added verification context for LLM');

    // Clean up - don't persist this context
    delete state.verificationContext;
  } else if (state.verificationContext && !isVerificationRelevant) {
    // Active flow is not verification-relevant (e.g., stock) â€” skip and clean up
    console.log(`ðŸš« [BuildLLMRequest] Skipped verification context â€” activeFlow="${state.activeFlow}" not in VERIFICATION_FLOWS`);
    delete state.verificationContext;
  }

  // Dispute context â€” LLM has anchor/truth data to reference
  if (state.disputeContext) {
    const dc = state.disputeContext;
    const disputeGuidance = `

## Ä°TÄ°RAZ BAÄžLAMI (Dispute Context)
KullanÄ±cÄ± Ã¶nceki sonucu reddediyor/itiraz ediyor.
- Ã–nceki akÄ±ÅŸ: ${dc.originalFlow || 'bilinmiyor'}
- Kargo takip bilgisi var mÄ±: ${dc.hasTrackingInfo ? 'EVET' : 'HAYIR'}

KURALLAR:
- KullanÄ±cÄ±nÄ±n itirazÄ±nÄ± ciddiye al
- Elindeki bilgileri (varsa kargo takip no) doÄŸal dille paylaÅŸ
- Geri arama teklif et
- Empati kur, "ama sistem ÅŸunu sÃ¶ylÃ¼yor" gibi savunmacÄ± olma`;

    enhancedSystemPrompt += disputeGuidance;
    console.log('âš ï¸ [BuildLLMRequest] Added dispute context for LLM');

    // Clean up
    delete state.disputeContext;
  }

  // Profanity strike context â€” LLM handles warning naturally
  if (routingResult?.routing?.routing?.profanityStrike) {
    const strike = routingResult.routing.routing.profanityStrike;
    const profanityGuidance = `

## KÃœFÃœR UYARISI
KullanÄ±cÄ± saygÄ±sÄ±z dil kullandÄ± (${strike}. uyarÄ± / 3 Ã¼zerinden).
- Kibarca uyar ama suÃ§lama
- YardÄ±m etmeye devam et
- DoÄŸal ve empatik ol`;

    enhancedSystemPrompt += profanityGuidance;
    console.log(`âš ï¸ [BuildLLMRequest] Added profanity context (strike ${strike}/3)`);
  }

  // STEP 0.5: CHATTER messages â€” CONTEXT-PRESERVING PROMPT
  // When chatterDirective is present (LLM mode), use directive-driven prompt.
  // Otherwise (legacy direct template mode that reached here), use generic chatter guidance.
  const isChatterRoute = routingResult?.isChatter || routingResult?.routing?.routing?.action === 'ACKNOWLEDGE_CHATTER';
  const chatterDirective = routingResult?.chatterDirective;

  if (chatterDirective) {
    // â”€â”€ LLM directive mode (flag ON) â”€â”€
    const assistantName = assistant?.name || 'Asistan';
    const businessName = business?.name || '';

    enhancedSystemPrompt += `

## CHATTER KISA YANIT MODU (LLM Directive)
- RolÃ¼n: ${businessName ? businessName + ' ÅŸirketinin' : 'ÅŸirketin'} mÃ¼ÅŸteri asistanÄ± ${assistantName}
- Mesaj tÃ¼rÃ¼: ${chatterDirective.kind} (greeting/thanks/generic)
- KonuÅŸma durumu: ${chatterDirective.flowStatus}
- Aktif gÃ¶rev var mÄ±: ${chatterDirective.activeTask ? 'EVET â€” ' + (chatterDirective.activeFlow || 'devam eden iÅŸ') : 'HAYIR'}
- DoÄŸrulama bekleniyor mu: ${chatterDirective.verificationPending ? 'EVET' : 'HAYIR'}

KURALLAR:
- Selam/teÅŸekkÃ¼re kÄ±sa ve doÄŸal cevap ver, robotik kalÄ±p kullanma.
- Maksimum ${chatterDirective.maxSentences} cÃ¼mle yaz.
- "Size nasÄ±l yardÄ±mcÄ± olabilirim?" veya benzer kliÅŸe yardÄ±m cÃ¼mlelerini TEKRARLAMA.
- EÄŸer aktif gÃ¶rev varsa, kÄ±sa yanÄ±t sonrasÄ± gÃ¶reve nazikÃ§e geri dÃ¶n.
- KullanÄ±cÄ± net bir talep vermediyse tek cÃ¼mlelik sÄ±cak bir karÅŸÄ±lÄ±k ver.

TON KISITLAMALARI:
- SatÄ±ÅŸ dili kullanma (no_salesy). "Harika fÄ±rsatlar", "kaÃ§Ä±rma" gibi ifadeler YASAK.
- Garip veya aÅŸÄ±rÄ± samimi selamlaÅŸmalardan kaÃ§Ä±n (no_weird_greetings). "CanÄ±m mÃ¼ÅŸterim", "tatlÄ±m" gibi ifadeler YASAK.
- AÅŸÄ±rÄ± dostane/informal olma (no_overfriendly). Profesyonel ama sÄ±cak bir ton koru.
- Ã–nceki selamlaÅŸmayÄ± birebir tekrarlama, ama tutarlÄ± bir ton ve Ã¼slup koru.`;
    console.log('ðŸ’¬ [BuildLLMRequest] CHATTER â€” LLM directive mode active');
  } else if (isChatterRoute) {
    // â”€â”€ Legacy mode (flag OFF, but reached LLM for some reason) â”€â”€
    const assistantName = assistant?.name || 'Asistan';
    const businessName = business?.name || '';
    const activeFlowSummary = state.activeFlow || state.flowStatus || 'none';
    const hasPendingVerification = state.verification?.status === 'pending';

    enhancedSystemPrompt += `

## CHATTER KISA YANIT MODU
- RolÃ¼n: ${businessName ? businessName + ' ÅŸirketinin' : 'ÅŸirketin'} mÃ¼ÅŸteri asistanÄ± ${assistantName}
- KonuÅŸma durumu: ${activeFlowSummary}
- DoÄŸrulama bekleniyor mu: ${hasPendingVerification ? 'EVET' : 'HAYIR'}

KURALLAR:
- Selam/teÅŸekkÃ¼re kÄ±sa ve doÄŸal cevap ver, robotik kalÄ±p kullanma.
- EÄŸer konuÅŸmada aktif bir gÃ¶rev varsa (Ã¶r: sipariÅŸ, doÄŸrulama), kÄ±sa yanÄ±t sonrasÄ± gÃ¶reve nazikÃ§e geri dÃ¶n.
- "Size nasÄ±l yardÄ±mcÄ± olabilirim?" cÃ¼mlesini her selamda tekrarlama.
- KullanÄ±cÄ± net bir talep vermediyse tek cÃ¼mlelik sÄ±cak bir karÅŸÄ±lÄ±k ver.`;
    console.log('ðŸ’¬ [BuildLLMRequest] CHATTER â€” context-preserving guidance aktif');
  }

  // ========================================
  // STOCK QUERY: Disambiguation & Disclosure Policy
  // ========================================
  // Inject instructions so LLM handles multi-match stock queries correctly
  // and never reveals raw stock quantities.
  enhancedSystemPrompt += `

## STOK SORGUSU KURALLARI

1. Tool "MULTIPLE_CANDIDATES" dÃ¶ndÃ¼ÄŸÃ¼nde: stok durumu hakkÄ±nda konuÅŸma, Ã¶nce Ã¼rÃ¼nÃ¼ netleÅŸtir. Tekrar tool Ã§aÄŸÄ±rÄ±rken aday listesindeki tam Ã¼rÃ¼n adÄ±nÄ± kullan.
2. Stok adedi (kaÃ§ adet/tane) ASLA paylaÅŸÄ±lmaz. Sadece "stokta mevcut / sÄ±nÄ±rlÄ± stok / stokta yok" bilgisi verilir.
3. MÃ¼ÅŸteri "kaÃ§ tane var?" diye sorarsa: kesin adet verilemeyeceÄŸini sÃ¶yle, ama belirli bir miktar ihtiyacÄ± varsa kontrol edebileceÄŸini belirt.
4. requested_qty parametresi SADECE mÃ¼ÅŸteri aÃ§Ä±k bir sayÄ± sÃ¶ylediÄŸinde doldurulur. "KaÃ§ tane var?" gibi genel sorularda BOÅž bÄ±rakÄ±lÄ±r.
5. Tool yanÄ±tÄ±ndaki quantity_check sonucunu kullan, kendi baÅŸÄ±na adet uydurma.`;

  // STEP 1: Apply tool gating policy
  const classifierConfidence = classification?.confidence || 0.9;

  // OPTIMIZATION: Skip tools entirely for CHATTER messages (greetings, acknowledgments)
  // This saves ~5000 tokens per CHATTER turn and reduces latency
  const isChatter = routingResult?.isChatter || routingResult?.routing?.routing?.action === 'ACKNOWLEDGE_CHATTER';

  let gatedTools;
  if (isChatter) {
    gatedTools = [];
    console.log('ðŸ’¬ [BuildLLMRequest] CHATTER detected â€” skipping all tools (0 token overhead)');
  } else {
    // P0-FIX: ALWAYS start from full tool list (allToolNames), not stale state.allowedTools.
    // Previously: state.allowedTools from prior turn was reused as input â†’ once a tool was gated out,
    // it could never come back (feedback loop). Now gating always evaluates from the full set.
    const allToolNames = toolsAll.map(t => t.function?.name).filter(Boolean);
    console.log('ðŸ”§ [BuildLLMRequest] toolsAll:', { count: toolsAll.length, names: allToolNames });

    const flowTools = allToolNames;

    gatedTools = applyToolGatingPolicy({
      confidence: classifierConfidence,
      activeFlow: state.activeFlow,
      allowedTools: flowTools,
      verificationStatus: state.verificationStatus,
      metrics
    });

    console.log('ðŸ”§ [BuildLLMRequest]:', {
      originalTools: flowTools.length,
      gatedTools: gatedTools.length,
      confidence: classifierConfidence.toFixed(2),
      removed: flowTools.filter(t => !gatedTools.includes(t))
    });
  }

  // STEP 2: Filter tools based on gated list
  // toolsAll is in OpenAI format: {type: 'function', function: {name, description, parameters}}
  const allowedToolObjects = toolsAll.filter(tool =>
    gatedTools.includes(tool.function?.name)
  );

  // STEP 3: Convert tools to Gemini format
  const geminiTools = allowedToolObjects.length > 0
    ? convertToolsToGemini(allowedToolObjects)
    : [];

  // STEP 4: Build conversation history for Gemini
  const geminiHistory = conversationHistory.map(msg => ({
    role: msg.role === 'assistant' ? 'model' : 'user',
    parts: [{ text: msg.content }]
  }));

  // STEP 5: Create Gemini chat session
  // Chatter-specific budget: lower tokens + temperature for cost/latency savings
  const isChatterLLM = !!chatterDirective;
  const generationConfig = isChatterLLM
    ? {
        temperature: 0.5,
        topP: 0.95,
        topK: 40,
        maxOutputTokens: 200,
        thinkingConfig: { thinkingBudget: 0 }
      }
    : {
        temperature: 0.7,
        topP: 0.95,
        topK: 40,
        maxOutputTokens: 1024,
        thinkingConfig: { thinkingBudget: 0 }
      };

  if (isChatterLLM) {
    console.log('ðŸ’¬ [BuildLLMRequest] CHATTER budget: maxOutputTokens=200, temperature=0.5');
  }

  const model = genAI.getGenerativeModel({
    model: 'gemini-2.5-flash',
    systemInstruction: enhancedSystemPrompt,
    tools: geminiTools.length > 0 ? [{ functionDeclarations: geminiTools }] : undefined,
    toolConfig: geminiTools.length > 0 ? {
      functionCallingConfig: {
        mode: 'AUTO'
      }
    } : undefined,
    generationConfig
  });

  const chat = model.startChat({
    history: geminiHistory
  });

  // STEP 6: Track gated tools in state (telemetry only, NOT used as input for next turn)
  // P0-FIX: Removed state.allowedTools feedback loop â€” was causing tools gated out once
  // to stay gated forever. Gating now always evaluates from full toolsAll set.
  state._lastGatedTools = gatedTools; // Underscore prefix = telemetry-only, not used as input

  return {
    chat,
    gatedTools,
    hasTools: gatedTools.length > 0,
    model,
    confidence: classifierConfidence
  };
}

export default { buildLLMRequest };
