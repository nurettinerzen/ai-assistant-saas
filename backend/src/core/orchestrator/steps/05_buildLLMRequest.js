/**
 * Step 5: Build LLM Request
 *
 * - Applies tool gating policy
 * - Builds Gemini request with gated tools
 * - Returns chat session and request configuration
 */

import { GoogleGenerativeAI } from '@google/generative-ai';
import { applyToolGatingPolicy } from '../../../policies/toolGatingPolicy.js';
import { convertToolsToGeminiFunctions as convertToolsToGemini } from '../../../services/gemini-utils.js';

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

export async function buildLLMRequest(params) {
  const {
    systemPrompt,
    conversationHistory,
    userMessage,
    classification,
    routingResult,
    state,
    toolsAll,
    metrics,
    assistant,
    business
  } = params;

  // STEP 0: Enhance system prompt with known customer info
  // SECURITY: Only send non-PII identifiers to LLM, not actual customer data
  let enhancedSystemPrompt = systemPrompt;
  if (state.extractedSlots && Object.keys(state.extractedSlots).length > 0) {
    const knownInfo = [];
    // Only include identifiers, not actual PII values
    if (state.extractedSlots.customer_name) {
      knownInfo.push(`Customer name mentioned`);
    }
    if (state.extractedSlots.phone) {
      knownInfo.push(`Phone number provided`);
    }
    if (state.extractedSlots.order_number) {
      knownInfo.push(`Order #${state.extractedSlots.order_number}`); // Order number is OK
    }
    if (state.extractedSlots.email) {
      knownInfo.push(`Email mentioned`);
    }

    if (knownInfo.length > 0) {
      enhancedSystemPrompt += `\n\nCustomer Context: ${knownInfo.join(', ')} - Use tools to retrieve actual data`;
      console.log('ðŸ“ [BuildLLMRequest] Added context flags (no PII):', knownInfo.length, 'indicators');
    }
  }

  // ========================================
  // ARCHITECTURE CHANGE: Inject verification & dispute context for LLM
  // ========================================
  // LLM now handles verification conversation naturally.
  // We inject context so it knows what's pending.
  if (state.verificationContext) {
    const vc = state.verificationContext;
    const verificationGuidance = `

## DOÄžRULAMA DURUMU (Verification Context)
- Durum: ${vc.status}
- Beklenen bilgi: ${vc.pendingField === 'name' ? 'Ad-soyad' : vc.pendingField === 'phone' ? 'Telefon numarasÄ±' : vc.pendingField}
- Deneme sayÄ±sÄ±: ${vc.attempts}/3

KURALLAR:
- KullanÄ±cÄ±nÄ±n son mesajÄ±nÄ± baÄŸlam iÃ§inde yorumla
- EÄŸer kullanÄ±cÄ± doÄŸrulama bilgisi verdiyse, customer_data_lookup tool'unu verification_input parametresiyle Ã§aÄŸÄ±r
- EÄŸer kullanÄ±cÄ± farklÄ± bir soru sorduysa, soruyu cevapla ama doÄŸrulama ihtiyacÄ±nÄ± da hatÄ±rlat
- AynÄ± cÃ¼mleyi tekrar etme â€” her seferinde farklÄ± ve doÄŸal konuÅŸ
- YanlÄ±ÅŸ anladÄ±ÄŸÄ±nÄ± fark edersen "SanÄ±rÄ±m bir karÄ±ÅŸÄ±klÄ±k oldu..." diyebilirsin
- "LÃ¼tfen ad-soyadÄ±nÄ±zÄ± yazÄ±nÄ±z" gibi form cÃ¼mleleri KULLANMA`;

    enhancedSystemPrompt += verificationGuidance;
    console.log('ðŸ” [BuildLLMRequest] Added verification context for LLM');

    // Clean up - don't persist this context
    delete state.verificationContext;
  }

  // Dispute context â€” LLM has anchor/truth data to reference
  if (state.disputeContext) {
    const dc = state.disputeContext;
    const disputeGuidance = `

## Ä°TÄ°RAZ BAÄžLAMI (Dispute Context)
KullanÄ±cÄ± Ã¶nceki sonucu reddediyor/itiraz ediyor.
- Ã–nceki akÄ±ÅŸ: ${dc.originalFlow || 'bilinmiyor'}
- Kargo takip bilgisi var mÄ±: ${dc.hasTrackingInfo ? 'EVET' : 'HAYIR'}

KURALLAR:
- KullanÄ±cÄ±nÄ±n itirazÄ±nÄ± ciddiye al
- Elindeki bilgileri (varsa kargo takip no) doÄŸal dille paylaÅŸ
- Geri arama teklif et
- Empati kur, "ama sistem ÅŸunu sÃ¶ylÃ¼yor" gibi savunmacÄ± olma`;

    enhancedSystemPrompt += disputeGuidance;
    console.log('âš ï¸ [BuildLLMRequest] Added dispute context for LLM');

    // Clean up
    delete state.disputeContext;
  }

  // Profanity strike context â€” LLM handles warning naturally
  if (routingResult?.routing?.routing?.profanityStrike) {
    const strike = routingResult.routing.routing.profanityStrike;
    const profanityGuidance = `

## KÃœFÃœR UYARISI
KullanÄ±cÄ± saygÄ±sÄ±z dil kullandÄ± (${strike}. uyarÄ± / 3 Ã¼zerinden).
- Kibarca uyar ama suÃ§lama
- YardÄ±m etmeye devam et
- DoÄŸal ve empatik ol`;

    enhancedSystemPrompt += profanityGuidance;
    console.log(`âš ï¸ [BuildLLMRequest] Added profanity context (strike ${strike}/3)`);
  }

  // STEP 0.5: CHATTER messages â€” MINIMAL PROMPT (izole test)
  // TÃ¼m system prompt'u override et, sadece tek paragraf ver
  const isChatterRoute = routingResult?.isChatter || routingResult?.routing?.routing?.action === 'ACKNOWLEDGE_CHATTER';
  if (isChatterRoute) {
    const assistantName = assistant?.name || 'Asistan';
    const businessName = business?.name || '';
    enhancedSystemPrompt = `Sen ${businessName ? businessName + ' ÅŸirketinin' : 'bir ÅŸirketin'} mÃ¼ÅŸteri asistanÄ± ${assistantName}'sÄ±n.
KullanÄ±cÄ± selamlaÅŸtÄ±ÄŸÄ±nda veya teÅŸekkÃ¼r ettiÄŸinde kÄ±sa ve doÄŸal yanÄ±t ver.`;
    console.log('ðŸ’¬ [BuildLLMRequest] CHATTER â€” minimal system prompt aktif (izole test)');
  }

  // STEP 1: Apply tool gating policy
  const classifierConfidence = classification?.confidence || 0.9;

  // OPTIMIZATION: Skip tools entirely for CHATTER messages (greetings, acknowledgments)
  // This saves ~5000 tokens per CHATTER turn and reduces latency
  const isChatter = routingResult?.isChatter || routingResult?.routing?.routing?.action === 'ACKNOWLEDGE_CHATTER';

  let gatedTools;
  if (isChatter) {
    gatedTools = [];
    console.log('ðŸ’¬ [BuildLLMRequest] CHATTER detected â€” skipping all tools (0 token overhead)');
  } else {
    // If no flow-specific tools, use ALL available tools (extract names from toolsAll)
    const allToolNames = toolsAll.map(t => t.function?.name).filter(Boolean);
    console.log('ðŸ”§ [BuildLLMRequest] toolsAll:', { count: toolsAll.length, names: allToolNames });

    const flowTools = (state.allowedTools && state.allowedTools.length > 0)
      ? state.allowedTools
      : allToolNames;

    gatedTools = applyToolGatingPolicy({
      confidence: classifierConfidence,
      activeFlow: state.activeFlow,
      allowedTools: flowTools,
      verificationStatus: state.verificationStatus,
      metrics
    });

    console.log('ðŸ”§ [BuildLLMRequest]:', {
      originalTools: flowTools.length,
      gatedTools: gatedTools.length,
      confidence: classifierConfidence.toFixed(2),
      removed: flowTools.filter(t => !gatedTools.includes(t))
    });
  }

  // STEP 2: Filter tools based on gated list
  // toolsAll is in OpenAI format: {type: 'function', function: {name, description, parameters}}
  const allowedToolObjects = toolsAll.filter(tool =>
    gatedTools.includes(tool.function?.name)
  );

  // STEP 3: Convert tools to Gemini format
  const geminiTools = allowedToolObjects.length > 0
    ? convertToolsToGemini(allowedToolObjects)
    : [];

  // STEP 4: Build conversation history for Gemini
  const geminiHistory = conversationHistory.map(msg => ({
    role: msg.role === 'assistant' ? 'model' : 'user',
    parts: [{ text: msg.content }]
  }));

  // STEP 5: Create Gemini chat session
  const model = genAI.getGenerativeModel({
    model: 'gemini-2.5-flash',
    systemInstruction: enhancedSystemPrompt,
    tools: geminiTools.length > 0 ? [{ functionDeclarations: geminiTools }] : undefined,
    toolConfig: geminiTools.length > 0 ? {
      functionCallingConfig: {
        mode: 'AUTO'
      }
    } : undefined,
    generationConfig: {
      temperature: 0.7,
      topP: 0.95,
      topK: 40,
      maxOutputTokens: 1024,
      // CRITICAL: Disable thinking mode to prevent empty responses with tool-enabled requests
      thinkingConfig: {
        thinkingBudget: 0
      }
    }
  });

  const chat = model.startChat({
    history: geminiHistory
  });

  // STEP 6: Update state with gated tools
  state.allowedTools = gatedTools;

  return {
    chat,
    gatedTools,
    hasTools: gatedTools.length > 0,
    model,
    confidence: classifierConfidence
  };
}

export default { buildLLMRequest };
