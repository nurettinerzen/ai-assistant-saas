/**
 * Step 5: Build LLM Request
 *
 * - Applies tool gating policy
 * - Builds Gemini request with gated tools
 * - Returns chat session and request configuration
 */

import { GoogleGenerativeAI } from '@google/generative-ai';
import { convertToolsToGeminiFunctions as convertToolsToGemini } from '../../../services/gemini-utils.js';
import { getEntityClarificationHint, getEntityHint, getEntityMatchType } from '../../../services/entityTopicResolver.js';
import { getFlow } from '../../../config/flow-definitions.js';

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

const FLOW_TOOL_OVERRIDES = Object.freeze({
  STOCK_CHECK: ['get_product_stock', 'check_stock_crm'],
  CALLBACK_REQUEST: ['create_callback']
});

function normalizeFlowName(flowName) {
  const normalized = String(flowName || '').toUpperCase();
  if (!normalized) return null;
  if (normalized === 'PRODUCT_INQUIRY') return 'PRODUCT_INFO';
  return normalized;
}

function normalizeFlowHeuristicText(message = '') {
  return String(message || '')
    .toLowerCase()
    .replace(/Ä±/g, 'i')
    .replace(/Ä°/g, 'i')
    .replace(/Ã¶/g, 'o')
    .replace(/Ã¼/g, 'u')
    .replace(/ÅŸ/g, 's')
    .replace(/Ã§/g, 'c')
    .replace(/ÄŸ/g, 'g')
    .replace(/[^\w\s]/g, ' ')
    .replace(/\s+/g, ' ')
    .trim();
}

function inferFlowFromMessage(message = '') {
  const text = normalizeFlowHeuristicText(message);
  if (!text) return null;

  if (/\b(stok|stock|envanter|available|availability|kac tane|kac adet|adet|tane|kac var|ne kadar var)\b/.test(text)) {
    return 'STOCK_CHECK';
  }

  if (/\b(urun|product|model|ozellik|spec|garanti|warranty|renk|color|fiyat|price)\b/.test(text)) {
    return 'PRODUCT_INFO';
  }

  return null;
}

export function resolveFlowScopedTools({ state, classification, routingResult, userMessage = '', allToolNames = [] }) {
  const normalizedAllTools = Array.isArray(allToolNames) ? allToolNames.filter(Boolean) : [];
  if (normalizedAllTools.length === 0) {
    return {
      resolvedFlow: null,
      gatedTools: []
    };
  }

  const candidates = [
    state?.activeFlow,
    routingResult?.routing?.routing?.suggestedFlow,
    classification?.suggestedFlow,
    inferFlowFromMessage(userMessage)
  ].map(normalizeFlowName).filter(Boolean);

  const resolvedFlow = candidates[0] || null;
  if (!resolvedFlow) {
    return {
      resolvedFlow: null,
      gatedTools: normalizedAllTools
    };
  }

  const overrideTools = FLOW_TOOL_OVERRIDES[resolvedFlow];
  const flowTools = Array.isArray(overrideTools) && overrideTools.length > 0
    ? overrideTools
    : getFlow(resolvedFlow)?.allowedTools || [];

  if (flowTools.length === 0) {
    return {
      resolvedFlow,
      gatedTools: normalizedAllTools
    };
  }

  let gatedTools = normalizedAllTools.filter(tool => flowTools.includes(tool));

  // Safety hard-stop: product/stock flows must not expose customer lookup tooling.
  if (resolvedFlow === 'PRODUCT_INFO' || resolvedFlow === 'STOCK_CHECK') {
    gatedTools = gatedTools.filter(tool => tool !== 'customer_data_lookup');
  }

  return {
    resolvedFlow,
    gatedTools
  };
}

export async function buildLLMRequest(params) {
  const {
    systemPrompt,
    conversationHistory,
    userMessage,
    classification,
    routingResult,
    state,
    toolsAll,
    metrics,
    assistant,
    business,
    entityResolution
  } = params;

  // STEP 0: Enhance system prompt with known customer info
  // SECURITY: Only send non-PII identifiers to LLM, not actual customer data
  let enhancedSystemPrompt = systemPrompt;
  if (state.extractedSlots && Object.keys(state.extractedSlots).length > 0) {
    const knownInfo = [];
    // Only include identifiers, not actual PII values
    if (state.extractedSlots.customer_name) {
      knownInfo.push(`Customer name mentioned`);
    }
    if (state.extractedSlots.phone) {
      knownInfo.push(`Phone number provided`);
    }
    if (state.extractedSlots.order_number) {
      knownInfo.push(`Order #${state.extractedSlots.order_number}`); // Order number is OK
    }
    if (state.extractedSlots.email) {
      knownInfo.push(`Email mentioned`);
    }

    if (knownInfo.length > 0) {
      enhancedSystemPrompt += `\n\nCustomer Context: ${knownInfo.join(', ')} - Use tools to retrieve actual data`;
      console.log('ðŸ“ [BuildLLMRequest] Added context flags (no PII):', knownInfo.length, 'indicators');
    }
  }

  // Callback precondition guidance (belt-and-suspenders with toolLoop precondition check)
  // LLM should ask for name/phone BEFORE calling create_callback
  if (!state.extractedSlots?.customer_name || !state.extractedSlots?.phone) {
    enhancedSystemPrompt += `\n\nKRÄ°TÄ°K: create_callback aracÄ±nÄ± Ã§aÄŸÄ±rmadan Ã–NCE mÃ¼ÅŸterinin adÄ±nÄ± ve telefon numarasÄ±nÄ± Ã¶ÄŸren. Bu bilgiler olmadan geri arama kaydÄ± oluÅŸturamazsÄ±n.`;
  }

  if (state.callbackFlow?.pending || state.activeFlow === 'CALLBACK_REQUEST') {
    enhancedSystemPrompt += `

## CALLBACK AKIÅžI (DETERMINISTIC)
- Bu konuÅŸma geri arama talebi akÄ±ÅŸÄ±nda.
- SADECE ad-soyad ve telefon bilgisini topla.
- SipariÅŸ numarasÄ±, telefon son 4, kimlik doÄŸrulama isteme.
- create_callback Ã§aÄŸrÄ±sÄ±nda topic sorusu sorma; topic otomatik Ã¼retilecek.
- Ad-soyad ve telefon mevcutsa create_callback Ã§aÄŸÄ±r, yoksa sadece eksik alanÄ± sor.`;
  }

  // ========================================
  // KB_ONLY MODE: Inject channel restriction prompt
  // ========================================
  if (params.channelMode === 'KB_ONLY') {
    const linksList = Object.entries(params.helpLinks || {})
      .filter(([, v]) => v)
      .map(([k, v]) => `- ${k}: ${v}`)
      .join('\n');

    enhancedSystemPrompt += `

## KB_ONLY MOD (KRÄ°TÄ°K!)
Bu kanal sadece bilgi bankasÄ± ve genel yardÄ±m iÃ§in aÃ§Ä±ktÄ±r.

YASAKLAR:
- KiÅŸisel sipariÅŸ/Ã¶deme/iade/kargo bilgisi verme
- "Kontrol ediyorum", "bakÄ±yorum" gibi tool varmÄ±ÅŸ gibi davranma
- SipariÅŸ durumu, teslimat tarihi, Ã¶deme tutarÄ± gibi claim yapma
- Link uydurma â€” sadece aÅŸaÄŸÄ±daki linkleri kullan

${linksList ? `YARDIM LÄ°NKLERÄ°:\n${linksList}` : 'Link bilgisi yok â€” "destek ekibimize ulaÅŸabilirsiniz" yÃ¶nlendirmesi yap.'}

DAVRANIÅž:
- Genel bilgi sorularÄ±na (iade sÃ¼resi, kargo politikasÄ±, Ã¼yelik) Bilgi BankasÄ±'ndan cevap ver
- KiÅŸisel veri sorusu gelirse: kÄ±sa sÄ±nÄ±r aÃ§Ä±kla + yardÄ±m linki/destek yÃ¶nlendirmesi yap
- DoÄŸal ve kÄ±sa konuÅŸ, robotik olma`;

    console.log('ðŸ”’ [BuildLLMRequest] KB_ONLY prompt injected');
  }

  // ========================================
  // ARCHITECTURE CHANGE: Inject verification & dispute context for LLM
  // ========================================
  // LLM now handles verification conversation naturally.
  // We inject context so it knows what's pending.
  // SCOPE: Only inject for flows that actually require PII verification.
  // Stock, product inquiry etc. should NEVER see verification guidance.
  const VERIFICATION_FLOWS = ['ORDER_STATUS', 'DEBT_INQUIRY', 'TRACKING_INFO', 'ACCOUNT_LOOKUP'];
  // Only inject verification guidance if we're actually in a verification-relevant flow.
  // When activeFlow is null (e.g. after post-result reset), also check if there's a recent
  // stock context â€” if so, this is NOT a verification scenario.
  const hasRecentStockContext = !!state.lastStockContext || state.anchor?.type === 'STOCK';
  const verificationFlowHint = normalizeFlowName(
    state.activeFlow ||
    routingResult?.routing?.routing?.suggestedFlow ||
    classification?.suggestedFlow
  );
  const isVerificationRelevant = !hasRecentStockContext &&
    VERIFICATION_FLOWS.includes(String(verificationFlowHint || ''));

  if (state.verificationContext && isVerificationRelevant) {
    const vc = state.verificationContext;
    const verificationGuidance = `

## DOÄžRULAMA DURUMU (Verification Context)
- Durum: ${vc.status}
- Beklenen bilgi: ${vc.pendingField === 'name' ? 'Ad-soyad' : vc.pendingField === 'phone' ? 'Telefon numarasÄ±' : vc.pendingField}
- Deneme sayÄ±sÄ±: ${vc.attempts}/3

KURALLAR:
- KullanÄ±cÄ±nÄ±n son mesajÄ±nÄ± baÄŸlam iÃ§inde yorumla
- EÄŸer kullanÄ±cÄ± doÄŸrulama bilgisi verdiyse, customer_data_lookup tool'unu verification_input parametresiyle Ã§aÄŸÄ±r
- EÄŸer kullanÄ±cÄ± farklÄ± bir soru sorduysa, soruyu cevapla ama doÄŸrulama ihtiyacÄ±nÄ± da hatÄ±rlat
- AynÄ± cÃ¼mleyi tekrar etme â€” her seferinde farklÄ± ve doÄŸal konuÅŸ
- YanlÄ±ÅŸ anladÄ±ÄŸÄ±nÄ± fark edersen kibarca dÃ¼zelt
- Form cÃ¼mleleri KULLANMA â€” sohbet gibi sor`;

    enhancedSystemPrompt += verificationGuidance;
    console.log('ðŸ” [BuildLLMRequest] Added verification context for LLM');

    // Clean up - don't persist this context
    delete state.verificationContext;
  } else if (state.verificationContext && !isVerificationRelevant) {
    // Active flow is not verification-relevant (e.g., stock) â€” skip and clean up
    console.log(`ðŸš« [BuildLLMRequest] Skipped verification context â€” activeFlow="${state.activeFlow}" not in VERIFICATION_FLOWS`);
    delete state.verificationContext;
  }

  // Dispute context â€” LLM has anchor/truth data to reference
  if (state.disputeContext) {
    const dc = state.disputeContext;
    const disputeGuidance = `

## Ä°TÄ°RAZ BAÄžLAMI (Dispute Context)
KullanÄ±cÄ± Ã¶nceki sonucu reddediyor/itiraz ediyor.
- Ã–nceki akÄ±ÅŸ: ${dc.originalFlow || 'bilinmiyor'}
- Kargo takip bilgisi var mÄ±: ${dc.hasTrackingInfo ? 'EVET' : 'HAYIR'}

KURALLAR:
- KullanÄ±cÄ±nÄ±n itirazÄ±nÄ± ciddiye al
- Elindeki bilgileri (varsa kargo takip no) doÄŸal dille paylaÅŸ
- Geri arama teklif et
- Empati kur, "ama sistem ÅŸunu sÃ¶ylÃ¼yor" gibi savunmacÄ± olma`;

    enhancedSystemPrompt += disputeGuidance;
    console.log('âš ï¸ [BuildLLMRequest] Added dispute context for LLM');

    // Clean up
    delete state.disputeContext;
  }

  // Profanity strike context â€” LLM handles warning naturally
  if (routingResult?.routing?.routing?.profanityStrike) {
    const strike = routingResult.routing.routing.profanityStrike;
    const profanityGuidance = `

## KÃœFÃœR UYARISI
KullanÄ±cÄ± saygÄ±sÄ±z dil kullandÄ± (${strike}. uyarÄ± / 3 Ã¼zerinden).
- Kibarca uyar ama suÃ§lama
- YardÄ±m etmeye devam et
- DoÄŸal ve empatik ol`;

    enhancedSystemPrompt += profanityGuidance;
    console.log(`âš ï¸ [BuildLLMRequest] Added profanity context (strike ${strike}/3)`);
  }

  if (routingResult?.isKbOnlyRedirect && routingResult?.kbOnlyRedirect) {
    const category = routingResult.kbOnlyRedirect.category || 'UNKNOWN';
    const variables = routingResult.kbOnlyRedirect.variables || {};
    enhancedSystemPrompt += `

## KB_ONLY REDIRECT CONTEXT
- category: ${category}
- supportLink: ${variables.supportLink || '-'}
- trackingLink: ${variables.trackingLink || '-'}
- returnLink: ${variables.returnLink || '-'}
- paymentLink: ${variables.paymentLink || '-'}

KURAL:
- Hesap/sipariÅŸe Ã¶zel iÅŸlem yapma.
- KÄ±sa, net bir yÃ¶nlendirme ver.
- Tek bir gÃ¼venli sonraki adÄ±m Ã¶ner.`;
    console.log('ðŸ”’ [BuildLLMRequest] Added KB_ONLY redirect context');
  }

  // Entity resolver output is structural hint only; LLM decides final wording.
  const resolverMatchType = getEntityMatchType(entityResolution);
  const resolverEntityHint = getEntityHint(entityResolution);
  const resolverClarificationHint = getEntityClarificationHint(entityResolution);
  if (resolverMatchType !== 'NONE' || entityResolution?.needsClarification) {
    enhancedSystemPrompt += `

## ENTITY RESOLVER HINT (STRUCTURED, NO DIRECT REPLY)
- matchType: ${resolverMatchType}
- entityHint: ${resolverEntityHint || '-'}
- confidence: ${entityResolution?.confidence ?? 0}
- needsClarification: ${entityResolution?.needsClarification ? 'YES' : 'NO'}
- clarificationQuestionHint: ${resolverClarificationHint || '-'}

KURAL:
- Resolver sonucu SADECE baÄŸlam ipucudur, cevabÄ± sen Ã¼retirsin.
- needsClarification=YES ise TEK bir netleÅŸtirme sorusu sor.
- OUT_OF_SCOPE ise iÅŸletme kapsamÄ±na nazikÃ§e geri yÃ¶nlendir.
- FUZZY_MATCH ise "${resolverEntityHint || 'bu varlÄ±k'}" iÃ§in doÄŸrulayÄ±cÄ± kÄ±sa soru sor.`;
    console.log('ðŸ§­ [BuildLLMRequest] Added structured entity resolver hint');
  }

  // STEP 0.5: CHATTER messages â€” LLM short response mode (always LLM)
  const isChatterRoute = routingResult?.isChatter || routingResult?.routing?.routing?.action === 'ACKNOWLEDGE_CHATTER';
  const chatterDirective = routingResult?.chatterDirective;

  if (chatterDirective) {
    const assistantName = assistant?.name || 'Asistan';
    const businessName = business?.name || '';

    // Tekrar algÄ±lama: son assistant cevaplarÄ±ndan benzersiz olanlarÄ± bul
    const recentAssistantMsgs = conversationHistory
      .filter(m => m.role === 'assistant')
      .map(m => String(m.content || '').trim())
      .slice(-5);
    const uniqueResponses = [...new Set(recentAssistantMsgs)];
    const hasRepetition = recentAssistantMsgs.length >= 2 && uniqueResponses.length < recentAssistantMsgs.length;
    const repeatedPhrase = hasRepetition ? uniqueResponses[uniqueResponses.length - 1] : null;

    enhancedSystemPrompt += `

## CHATTER KISA YANIT MODU (LLM Directive)
- RolÃ¼n: ${businessName ? businessName + ' ÅŸirketinin' : 'ÅŸirketin'} mÃ¼ÅŸteri asistanÄ± ${assistantName}
- Mesaj tÃ¼rÃ¼: ${chatterDirective.kind} (greeting/thanks/generic)
- KonuÅŸma durumu: ${chatterDirective.flowStatus}
- Aktif gÃ¶rev var mÄ±: ${chatterDirective.activeTask ? 'EVET â€” ' + (chatterDirective.activeFlow || 'devam eden iÅŸ') : 'HAYIR'}
- DoÄŸrulama bekleniyor mu: ${chatterDirective.verificationPending ? 'EVET' : 'HAYIR'}

KURALLAR:
- Selam/teÅŸekkÃ¼re kÄ±sa ve doÄŸal cevap ver.
- CevabÄ± 1-2 cÃ¼mle ile sÄ±nÄ±rla (${chatterDirective.maxSentences} cÃ¼mleyi aÅŸma).
- KÄ±sa selamdan sonra en fazla 1 net takip sorusu sor.
- Aktif gÃ¶rev varsa soruyu o gÃ¶reve geri baÄŸla.
- Backend ÅŸablonlarÄ±nÄ± tekrar etme, cevabÄ± doÄŸal varyasyonla kendin Ã¼ret.${hasRepetition ? `

âš ï¸ TEKRAR YASAÄžI (KRÄ°TÄ°K):
Ã–nceki cevaplarÄ±nda "${repeatedPhrase}" ifadesini ZATEN KULLANDIN.
Bu cevabÄ± veya benzerini TEKRAR KULLANMA.
FarklÄ± bir selamlama ve farklÄ± bir soru sor.
Ã–rnek varyasyonlar: "HoÅŸ geldin!", "Tekrar merhaba!", "Selamlar!", "Hey, nasÄ±l yardÄ±mcÄ± olabilirim?", "Buyur, dinliyorum!"` : ''}`;
    console.log(`ðŸ’¬ [BuildLLMRequest] CHATTER â€” LLM directive mode active${hasRepetition ? ' (anti-repeat injected)' : ''}`);
  } else if (isChatterRoute) {
    const assistantName = assistant?.name || 'Asistan';
    const businessName = business?.name || '';
    const activeFlowSummary = state.activeFlow || state.flowStatus || 'none';
    const hasPendingVerification = state.verification?.status === 'pending';

    enhancedSystemPrompt += `

## CHATTER KISA YANIT MODU
- RolÃ¼n: ${businessName ? businessName + ' ÅŸirketinin' : 'ÅŸirketin'} mÃ¼ÅŸteri asistanÄ± ${assistantName}
- KonuÅŸma durumu: ${activeFlowSummary}
- DoÄŸrulama bekleniyor mu: ${hasPendingVerification ? 'EVET' : 'HAYIR'}

KURALLAR:
- Selam/teÅŸekkÃ¼re kÄ±sa ve doÄŸal cevap ver, robotik kalÄ±p kullanma.
- CevabÄ± 1-2 cÃ¼mlede tut.
- KÄ±sa selamdan sonra en fazla 1 net takip sorusu sor.
- EÄŸer konuÅŸmada aktif bir gÃ¶rev varsa (Ã¶r: sipariÅŸ, doÄŸrulama), soruyu gÃ¶reve geri baÄŸla.`;
    console.log('ðŸ’¬ [BuildLLMRequest] CHATTER â€” context-preserving guidance aktif');
  }

  // ========================================
  // STOCK QUERY: Disambiguation & Disclosure Policy
  // ========================================
  // Inject instructions so LLM handles multi-match stock queries correctly
  // and never reveals raw stock quantities.
  enhancedSystemPrompt += `

## STOK SORGUSU KURALLARI

1. Tool "MULTIPLE_CANDIDATES" dÃ¶ndÃ¼ÄŸÃ¼nde: stok durumu hakkÄ±nda konuÅŸma, Ã¶nce Ã¼rÃ¼nÃ¼ netleÅŸtir. Tekrar tool Ã§aÄŸÄ±rÄ±rken aday listesindeki tam Ã¼rÃ¼n adÄ±nÄ± kullan.
2. Stok adedi (kaÃ§ adet/tane) ASLA paylaÅŸÄ±lmaz. Sadece "stokta mevcut / sÄ±nÄ±rlÄ± stok / stokta yok" bilgisi verilir.
3. MÃ¼ÅŸteri "kaÃ§ tane var?" diye sorarsa: kesin adet verilemeyeceÄŸini sÃ¶yle, ama belirli bir miktar ihtiyacÄ± varsa kontrol edebileceÄŸini belirt.
4. requested_qty parametresi SADECE mÃ¼ÅŸteri aÃ§Ä±k bir sayÄ± sÃ¶ylediÄŸinde doldurulur. "KaÃ§ tane var?" gibi genel sorularda BOÅž bÄ±rakÄ±lÄ±r.
5. Tool yanÄ±tÄ±ndaki quantity_check sonucunu kullan, kendi baÅŸÄ±na adet uydurma.`;

  const classifierConfidence = classification?.confidence || 0.9;

  enhancedSystemPrompt += `

## TOOL KULLANIM KURALI (LLM AUTHORITY)
- Tool kullanmadan doÄŸru ve gÃ¼venli cevap verebiliyorsan tool Ã‡AÄžIRMA.
- Tool gerekiyorsa Ã¶nce SADECE BÄ°R eksik bilgiyi sor â€” birden fazla bilgiyi aynÄ± anda isteme.
- SipariÅŸ sorgusu: SADECE sipariÅŸ numarasÄ± sor. Telefon, isim, soyisim isteme. SÄ±ra: sipariÅŸ no â†’ doÄŸrulama (sistem otomatik isteyecek).
- Eksik bilgi tamamlanmadan tool Ã§aÄŸÄ±rma.
- Tool sonucu olmadan hesap/sipariÅŸ/kiÅŸisel claim Ã¼retme.`;

  // LLM decides whether to call tools; backend only passes allowlisted tools.
  const allToolNames = toolsAll.map(t => t.function?.name).filter(Boolean);
  const { gatedTools, resolvedFlow } = resolveFlowScopedTools({
    state,
    classification,
    routingResult,
    userMessage,
    allToolNames
  });
  metrics.toolDecisionMode = 'llm_authority_allowlist_only';
  console.log('ðŸ”§ [BuildLLMRequest] Allowlist tools passed to LLM:', {
    count: gatedTools.length,
    names: gatedTools,
    resolvedFlow: resolvedFlow || 'NONE'
  });

  metrics.flowScopedTools = {
    resolvedFlow: resolvedFlow || null,
    allToolCount: allToolNames.length,
    gatedToolCount: gatedTools.length
  };

  // STEP 2: Filter tools based on gated list
  // toolsAll is in OpenAI format: {type: 'function', function: {name, description, parameters}}
  const allowedToolObjects = toolsAll.filter(tool =>
    gatedTools.includes(tool.function?.name)
  );

  // STEP 3: Convert tools to Gemini format
  const geminiTools = allowedToolObjects.length > 0
    ? convertToolsToGemini(allowedToolObjects)
    : [];

  // STEP 4: Build conversation history for Gemini
  const geminiHistory = conversationHistory.map(msg => ({
    role: msg.role === 'assistant' ? 'model' : 'user',
    parts: [{ text: msg.content }]
  }));

  // STEP 5: Create Gemini chat session
  // Chatter-specific budget: lower tokens + temperature for cost/latency savings
  const isChatterLLM = !!chatterDirective;
  const generationConfig = isChatterLLM
    ? {
        temperature: 0.8,
        topP: 0.95,
        topK: 40,
        maxOutputTokens: 200,
        thinkingConfig: { thinkingBudget: 0 }
      }
    : {
        temperature: 0.7,
        topP: 0.95,
        topK: 40,
        maxOutputTokens: 1024,
        thinkingConfig: { thinkingBudget: 0 }
      };

  if (isChatterLLM) {
    console.log('ðŸ’¬ [BuildLLMRequest] CHATTER budget: maxOutputTokens=200, temperature=0.8');
  }

  const model = genAI.getGenerativeModel({
    model: 'gemini-2.5-flash',
    systemInstruction: enhancedSystemPrompt,
    tools: geminiTools.length > 0 ? [{ functionDeclarations: geminiTools }] : undefined,
    toolConfig: geminiTools.length > 0 ? {
      functionCallingConfig: {
        mode: 'AUTO'
      }
    } : undefined,
    generationConfig
  });

  const chat = model.startChat({
    history: geminiHistory
  });

  // STEP 6: Track gated tools in state (telemetry only, NOT used as input for next turn)
  // P0-FIX: Removed state.allowedTools feedback loop â€” was causing tools gated out once
  // to stay gated forever. Gating now always evaluates from full toolsAll set.
  state._lastGatedTools = gatedTools; // Underscore prefix = telemetry-only, not used as input

  return {
    chat,
    gatedTools,
    hasTools: gatedTools.length > 0,
    model,
    confidence: classifierConfidence
  };
}

export default { buildLLMRequest };
